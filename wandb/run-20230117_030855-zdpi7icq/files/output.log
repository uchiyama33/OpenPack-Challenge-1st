GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/usr/local/lib/python3.8/dist-packages/torch/nn/init.py:388: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/usr/local/lib/python3.8/dist-packages/torch/nn/init.py:426: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
[2023-01-17 03:09:00,244][__main__][INFO] - Start training for 200 epochs (k=0).
2023-01-17 03:09:00 | INFO | __main__ | Start training for 200 epochs (k=0).
[2023-01-17 03:09:17,382][utils.datamodule][INFO] - dataset[train]: OpenPackImu(num_sequence=45, submission=False)
[2023-01-17 03:09:17,383][utils.datamodule][INFO] - dataset[val]: OpenPackImu(num_sequence=10, submission=False)
[2023-01-17 03:09:17,383][utils.datamodule][INFO] - dataset[test]: None
[2023-01-17 03:09:17,383][utils.datamodule][INFO] - dataset[submission]: None
Sanity Checking: 0it [00:00, ?it/s]
2023-01-17 03:09:17 | INFO | utils.datamodule | dataset[train]: OpenPackImu(num_sequence=45, submission=False)
2023-01-17 03:09:17 | INFO | utils.datamodule | dataset[val]: OpenPackImu(num_sequence=10, submission=False)
2023-01-17 03:09:17 | INFO | utils.datamodule | dataset[test]: None
2023-01-17 03:09:17 | INFO | utils.datamodule | dataset[submission]: None
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name              | Type                          | Params
--------------------------------------------------------------------
0 | net               | myConvTransformerAVECplusLSTM | 231 M
1 | criterion_test    | CrossEntropyLoss              | 0
2 | criterion_w_kappa | OpWeightedKappaLoss           | 0
3 | criterion         | CrossEntropyLoss              | 0
--------------------------------------------------------------------
231 M     Trainable params
0         Non-trainable params
231 M     Total params
926.199   Total estimated model params size (MB)
/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/data.py:135: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.
  rank_zero_warn(
/usr/local/lib/python3.8/dist-packages/lightning_lite/utilities/data.py:63: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.
Sanity Checking DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  7.42it/s][2023-01-17 03:09:18,330][utils.lightning_module][INFO] - Epoch[000] TRAIN: loss=-1.0000, acc=-1.0000 | VAL: loss= 2.3951, acc= 0.0605, f1macro= 0.0124
Epoch 0:   0%|                                                                                                                                                           | 0/69 [00:00<?, ?it/s]











Epoch 0:  97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 67/69 [00:25<00:00,  2.63it/s, loss=2.26, v_num=7icq]
Validation DataLoader 0:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 11/13 [00:01<00:00,  8.81it/s]












Epoch 1:  81%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 56/69 [00:24<00:05,  2.33it/s, loss=2.19, v_num=7icq]


Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 69/69 [00:26<00:00,  2.63it/s, loss=2.19, v_num=7icq]












Epoch 2:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 63/69 [00:26<00:02,  2.42it/s, loss=2.04, v_num=7icq]

Epoch 2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 69/69 [00:26<00:00,  2.60it/s, loss=2.04, v_num=7icq]












Epoch 3:  94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 65/69 [00:25<00:01,  2.52it/s, loss=1.87, v_num=7icq]

Epoch 3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 69/69 [00:26<00:00,  2.65it/s, loss=1.87, v_num=7icq]












Epoch 4:  94%|▉| 65/69 [00:25<00:01,  2.52it/s,

Epoch 4: 100%|█| 69/69 [00:26<00:00,  2.65it/s,
2023-01-17 03:11:44 | INFO | utils.lightning_module | Epoch[004] TRAIN: loss= 1.9313, acc= 0.4595 | VAL: loss= 1.1116, acc= 0.6066, f1macro= 0.5215
/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Traceback (most recent call last):
  File "/workspace/src/train.py", line 122, in <module>
    main()
  File "/usr/local/lib/python3.8/dist-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/usr/local/lib/python3.8/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/usr/local/lib/python3.8/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/usr/local/lib/python3.8/dist-packages/hydra/_internal/utils.py", line 219, in run_and_report
    return func()
  File "/usr/local/lib/python3.8/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/usr/local/lib/python3.8/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/workspace/src/train.py", line 93, in main
    plmodel = TransformerPL(cfg).to(dtype=torch.float, device=device)
  File "/usr/local/lib/python3.8/dist-packages/openpack_torch/lightning.py", line 23, in __init__
    self.net: nn.Module = self.init_model(cfg)
  File "/workspace/src/utils/lightning_module.py", line 147, in init_model
    model = myConvTransformerAVECplusLSTM(
  File "/workspace/src/utils/model.py", line 2349, in __init__
    self.lstm = nn.LSTM(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py", line 613, in __init__
    super(LSTM, self).__init__('LSTM', *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py", line 124, in __init__
    self.reset_parameters()
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py", line 196, in reset_parameters
    init.uniform_(weight, -stdv, stdv)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/init.py", line 135, in uniform_
    return _no_grad_uniform_(tensor, a, b)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/init.py", line 14, in _no_grad_uniform_
    return tensor.uniform_(a, b)
KeyboardInterrupt
Traceback (most recent call last):
  File "/workspace/src/train.py", line 122, in <module>
    main()
  File "/usr/local/lib/python3.8/dist-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/usr/local/lib/python3.8/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/usr/local/lib/python3.8/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/usr/local/lib/python3.8/dist-packages/hydra/_internal/utils.py", line 219, in run_and_report
    return func()
  File "/usr/local/lib/python3.8/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/usr/local/lib/python3.8/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/workspace/src/train.py", line 93, in main
    plmodel = TransformerPL(cfg).to(dtype=torch.float, device=device)
  File "/usr/local/lib/python3.8/dist-packages/openpack_torch/lightning.py", line 23, in __init__
    self.net: nn.Module = self.init_model(cfg)
  File "/workspace/src/utils/lightning_module.py", line 147, in init_model
    model = myConvTransformerAVECplusLSTM(
  File "/workspace/src/utils/model.py", line 2349, in __init__
    self.lstm = nn.LSTM(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py", line 613, in __init__
    super(LSTM, self).__init__('LSTM', *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py", line 124, in __init__
    self.reset_parameters()
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py", line 196, in reset_parameters
    init.uniform_(weight, -stdv, stdv)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/init.py", line 135, in uniform_
    return _no_grad_uniform_(tensor, a, b)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/init.py", line 14, in _no_grad_uniform_
    return tensor.uniform_(a, b)
KeyboardInterrupt